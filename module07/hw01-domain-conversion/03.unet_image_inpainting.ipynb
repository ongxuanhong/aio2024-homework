{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqzvGPAAd9Hl"
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6475,
     "status": "ok",
     "timestamp": 1702624687725,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "IvLth2vNeA4M",
    "outputId": "42ec6b69-70bd-4990-cedf-1d7949cc23fd"
   },
   "outputs": [],
   "source": [
    "# Khoa_LHR_image.zip\n",
    "!gdown --id 1bsWkNmmYvBrgE1c58SGJFcCjQv3SUyH3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20522,
     "status": "ok",
     "timestamp": 1702624710504,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "87eimpdpShbc",
    "outputId": "ae7bde3c-1d78-43e0-e549-1283bc0377a6"
   },
   "outputs": [],
   "source": [
    "!pip install torcheval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PWfhiq4VqCZ"
   },
   "outputs": [],
   "source": [
    "!unzip /content/Khoa_LHR_image.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8548,
     "status": "ok",
     "timestamp": 1702624764962,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "tw2BTZNSeR2f",
    "outputId": "1dc01284-4dbb-4c37-ba4b-46949fb6ab06"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torcheval.metrics.functional import peak_signal_noise_ratio\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6RNPVANhAAm"
   },
   "source": [
    "## Problem3: Inpainting Image with UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHKeeZmyShbe"
   },
   "source": [
    "### Unet for inpainting image task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdkS1RcMShbf"
   },
   "source": [
    "#### No skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwRF6MIMShbf"
   },
   "outputs": [],
   "source": [
    "class FirstFeatureNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FirstFeatureNoSkip, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlockNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlockNoSkip, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class EncoderNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(EncoderNoSkip, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlockNoSkip(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DecoderNoSkip, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(in_channels, out_channels*2, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels*2),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.conv_block = ConvBlockNoSkip(out_channels*2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalOutputNoSkip(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FinalOutputNoSkip, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class II_Unet_NoSkip(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_channels=3, n_classes=3\n",
    "    ):\n",
    "        super(II_Unet_NoSkip, self).__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.in_conv1 = FirstFeatureNoSkip(n_channels, 64)\n",
    "        self.in_conv2 = ConvBlockNoSkip(64, 64)\n",
    "\n",
    "        self.enc_1 = EncoderNoSkip(64, 128)\n",
    "        self.enc_2 = EncoderNoSkip(128, 256)\n",
    "        self.enc_3 = EncoderNoSkip(256, 512)\n",
    "        self.enc_4 = EncoderNoSkip(512, 1024)\n",
    "\n",
    "        self.dec_1 = DecoderNoSkip(1024, 512)\n",
    "        self.dec_2 = DecoderNoSkip(512, 256)\n",
    "        self.dec_3 = DecoderNoSkip(256, 128)\n",
    "        self.dec_4 = DecoderNoSkip(128, 64)\n",
    "\n",
    "        self.out_conv = FinalOutputNoSkip(64, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv1(x)\n",
    "        x = self.in_conv2(x)\n",
    "\n",
    "        x = self.enc_1(x)\n",
    "        x = self.enc_2(x)\n",
    "        x = self.enc_3(x)\n",
    "        x = self.enc_4(x)\n",
    "\n",
    "        x = self.dec_1(x)\n",
    "        x = self.dec_2(x)\n",
    "        x = self.dec_3(x)\n",
    "        x = self.dec_4(x)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5914,
     "status": "ok",
     "timestamp": 1702624770874,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "ESmFdYV2Shbh",
    "outputId": "3c068e5d-840a-45b1-c716-b80c9220120d"
   },
   "outputs": [],
   "source": [
    "unet_model = II_Unet_NoSkip().to(device)\n",
    "img = torch.ones(2, 3, 256, 256).to(device)\n",
    "unet_model(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LmNgHf3Shbi"
   },
   "source": [
    "#### Skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6lMd1XRShbi"
   },
   "outputs": [],
   "source": [
    "class FirstFeature(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FirstFeature, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.conv(x)\n",
    "        x = torch.concat([x, skip], dim=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalOutput(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FinalOutput, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1, 0, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class II_Unet(nn.Module):\n",
    "    def __init__(\n",
    "            self, n_channels=3, n_classes=3, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(II_Unet, self).__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.in_conv1 = FirstFeature(n_channels, 64)\n",
    "        self.in_conv2 = ConvBlock(64, 64)\n",
    "\n",
    "        self.enc_1 = Encoder(64, 128)\n",
    "        self.enc_2 = Encoder(128, 256)\n",
    "        self.enc_3 = Encoder(256, 512)\n",
    "        self.enc_4 = Encoder(512, 1024)\n",
    "\n",
    "        self.dec_1 = Decoder(1024, 512)\n",
    "        self.dec_2 = Decoder(512, 256)\n",
    "        self.dec_3 = Decoder(256, 128)\n",
    "        self.dec_4 = Decoder(128, 64)\n",
    "\n",
    "        self.out_conv = FinalOutput(64, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_conv1(x)\n",
    "        x1 = self.in_conv2(x)\n",
    "\n",
    "        x2 = self.enc_1(x1)\n",
    "        x3 = self.enc_2(x2)\n",
    "        x4 = self.enc_3(x3)\n",
    "        x5 = self.enc_4(x4)\n",
    "\n",
    "        x = self.dec_1(x5, x4)\n",
    "        x = self.dec_2(x, x3)\n",
    "        x = self.dec_3(x, x2)\n",
    "        x = self.dec_4(x, x1)\n",
    "\n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4602,
     "status": "ok",
     "timestamp": 1702624775465,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "JZKCTR1oShbj",
    "outputId": "a98aa847-a12a-43bf-9df9-122a15dd72a2"
   },
   "outputs": [],
   "source": [
    "unet_model = II_Unet().to(device)\n",
    "img = torch.ones(2, 3, 256, 256).to(device)\n",
    "unet_model(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI4epg7chLe_"
   },
   "source": [
    "### Prepare Inpainting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7a6cU45Shbk"
   },
   "outputs": [],
   "source": [
    "LHR_TRAIN_DATA_PATH = '/content/Khoa_LHR_image/train'\n",
    "LHR_VAL_DATA_PATH = '/content/Khoa_LHR_image/val'\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KssodokkoH12"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    ############################## Your Code Here###########################\n",
    "    \"\"\"\n",
    "    Các bạn dựa vào idea hướng dẫn trong file mô tả bài hãy xây dựng một hàm load data\n",
    "    cho bài toán Image Inpainting (input_image=256x256 và target_image=256x256 ảnh màu).\n",
    "    Các bạn có thể tự do xây dựng theo từng cá nhân, có thể add thêm hoặc xoá các method không\n",
    "    cần thiết. Hoặc các bạn có thể tham khảo code hướng dẫn trong file mô tả bài tập\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, is_train=True):\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "    def normalize(self, input_image, target_image):\n",
    "\n",
    "\n",
    "    def random_jitter(self, input_image, target_image):\n",
    "\n",
    "\n",
    "    def create_mask(self, image):\n",
    "\n",
    "        return masked_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return input_image, target_image\n",
    "        ###############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYzYUdbcShbl"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(LHR_TRAIN_DATA_PATH, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = ImageDataset(LHR_VAL_DATA_PATH, is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dfDCDnpShbl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "executionInfo": {
     "elapsed": 5099,
     "status": "ok",
     "timestamp": 1702624801206,
     "user": {
      "displayName": "Khoa Nguyen Tho Anh",
      "userId": "05392028195404260378"
     },
     "user_tz": -420
    },
    "id": "5hk4N3JeShbl",
    "outputId": "266040dc-25c7-41d8-936b-932f5dc6844b"
   },
   "outputs": [],
   "source": [
    "in_batch, tar_batch = next(iter(train_loader))\n",
    "in_batch = (in_batch + 1)/2\n",
    "tar_batch = (tar_batch + 1)/2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.squeeze(in_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.squeeze(tar_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.squeeze(in_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.squeeze(tar_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkTc_zNOhRqG"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryp6yOlgpPmA"
   },
   "outputs": [],
   "source": [
    "def generate_images(model, inputs, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        predictions = model(inputs)\n",
    "    inputs, labels, predictions = inputs.cpu().numpy(), labels.cpu().numpy(), predictions.cpu().numpy()\n",
    "    plt.figure(figsize=(15,20))\n",
    "\n",
    "    display_list = [inputs[-1].transpose((1, 2, 0)), labels[-1].transpose((1, 2, 0)), predictions[-1].transpose((1, 2, 0))]\n",
    "    title = ['Input', 'Real', 'Predicted']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow((display_list[i] + 1) / 2)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWRss-mDpQUy"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_psnr, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_psnr += peak_signal_noise_ratio(predictions, labels)\n",
    "        total_count += 1\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| psnr {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_psnr / total_count\n",
    "                )\n",
    "            )\n",
    "            total_psnr, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_psnr = total_psnr / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_psnr, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swoAKY_1pTqY"
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, criterion, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    total_psnr, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "\n",
    "            total_psnr +=  peak_signal_noise_ratio(predictions, labels)\n",
    "            total_count += 1\n",
    "\n",
    "    epoch_psnr = total_psnr / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_psnr, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwv1pw5HpVdF"
   },
   "outputs": [],
   "source": [
    "def train(model, model_name, save_model, optimizer, criterion, train_dataloader, valid_dataloader, num_epochs, device):\n",
    "    train_psnrs, train_losses = [], []\n",
    "    eval_psnrs, eval_losses = [], []\n",
    "    best_psnr_eval = -1000\n",
    "    times = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training\n",
    "        train_psnr, train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device, epoch)\n",
    "        train_psnrs.append(train_psnr.cpu())\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluation\n",
    "        eval_psnr, eval_loss = evaluate_epoch(model, criterion, valid_dataloader, device)\n",
    "        eval_psnrs.append(eval_psnr.cpu())\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if best_psnr_eval < eval_psnr:\n",
    "            torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
    "            inputs_t, targets_t = next(iter(valid_dataloader))\n",
    "            generate_images(model, inputs_t, targets_t)\n",
    "            best_psnr_eval = eval_psnr\n",
    "        times.append(time.time() - epoch_start_time)\n",
    "        # Print loss, psnr end epoch\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| End of epoch {:3d} | Time: {:5.2f}s | Train psnr {:8.3f} | Train Loss {:8.3f} \"\n",
    "            \"| Valid psnr {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "                epoch, time.time() - epoch_start_time, train_psnr, train_loss, eval_psnr, eval_loss\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
    "    model.eval()\n",
    "    metrics = {\n",
    "        'train_psnr': train_psnrs,\n",
    "        'train_loss': train_losses,\n",
    "        'valid_psnr': eval_psnrs,\n",
    "        'valid_loss': eval_losses,\n",
    "        'time': times\n",
    "    }\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n09uZo3TpXHD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(num_epochs, train_psnrs, eval_psnrs, train_losses, eval_losses):\n",
    "    epochs = list(range(num_epochs))\n",
    "    fig, axs = plt.subplots(nrows = 1, ncols =2 , figsize = (12,6))\n",
    "    axs[0].plot(epochs, train_psnrs, label = \"Training\")\n",
    "    axs[0].plot(epochs, eval_psnrs, label = \"Evaluation\")\n",
    "    axs[1].plot(epochs, train_losses, label = \"Training\")\n",
    "    axs[1].plot(epochs, eval_losses, label = \"Evaluation\")\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"PSNR\")\n",
    "    axs[1].set_ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GStwoqvApYxH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_and_display(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(test_dataloader):\n",
    "            if idx >= 10:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            predictions = model(inputs)\n",
    "            generate_images(model, inputs, labels)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84aIuhkhhhM8"
   },
   "source": [
    "#### Unet No Skip Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ROK-qJopaq0"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IP_unet_model_noskip = II_Unet_NoSkip().to(device)\n",
    "IP_unet_model_noskip.to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(IP_unet_model_noskip.parameters(), lr=1e-4, betas=[0.5,0.999])\n",
    "\n",
    "save_model = './UNET'\n",
    "os.makedirs(save_model, exist_ok = True)\n",
    "\n",
    "EPOCHS = 100\n",
    "IP_unet_model_noskip, metrics = train(\n",
    "    IP_unet_model_noskip, 'IP_unet_model_noskip', save_model, optimizer, criterion, train_loader, test_loader, EPOCHS, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cYg-gi2pmB4",
    "outputId": "650a96ed-39b7-41c2-d5af-e33df4a15efe"
   },
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    EPOCHS,\n",
    "    metrics[\"train_psnr\"],\n",
    "    metrics[\"valid_psnr\"],\n",
    "    metrics[\"train_loss\"],\n",
    "    metrics[\"valid_loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FaTLX6Ypl1n",
    "outputId": "082bf7e3-0bd0-4258-ce78-ffabc55db9d5"
   },
   "outputs": [],
   "source": [
    "test_psnr, test_loss = evaluate_epoch(IP_unet_model_noskip, criterion, test_loader, device)\n",
    "test_psnr, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0_53s3Wplm2",
    "outputId": "6b2ca804-f96a-47a7-87cf-6fe950aaade9"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model_noskip, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3cY-Ljspj3i",
    "outputId": "50a40840-6de2-4bf8-cd71-e9054aaa0369"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model_noskip, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFsmA8jUhlO8"
   },
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBpd1uJfxqsT",
    "outputId": "e275c4a2-93df-43a4-cd20-53ecc447c27c"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IP_unet_model = II_Unet().to(device)\n",
    "IP_unet_model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(IP_unet_model.parameters(), lr=1e-4, betas=[0.5,0.999])\n",
    "\n",
    "save_model = './UNET'\n",
    "os.makedirs(save_model, exist_ok = True)\n",
    "\n",
    "EPOCHS = 100\n",
    "IP_unet_model, metrics = train(\n",
    "    IP_unet_model, 'IP_unet_model', save_model, optimizer, criterion, train_loader, test_loader, EPOCHS, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF7z1p-KxqsT",
    "outputId": "df806402-b93e-4a24-9556-722fa87938b8"
   },
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    EPOCHS,\n",
    "    metrics[\"train_psnr\"],\n",
    "    metrics[\"valid_psnr\"],\n",
    "    metrics[\"train_loss\"],\n",
    "    metrics[\"valid_loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSQviQ5hxqsU",
    "outputId": "3dc6afc9-a160-4f59-d687-7952da75613a"
   },
   "outputs": [],
   "source": [
    "test_psnr, test_loss = evaluate_epoch(IP_unet_model, criterion, test_loader, device)\n",
    "test_psnr, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTkdxq7exqsU",
    "outputId": "b030ae70-3fd2-4bd6-cdb9-884d9f32ec4d"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zq9FVj1jxqsU",
    "outputId": "4069e3c5-7314-4cab-f2ed-31d366c99b5e"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K9Uz2PKxqsV"
   },
   "source": [
    "#### Unet Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqlFwqj7xqsV"
   },
   "outputs": [],
   "source": [
    "LHR_TRAIN_DATA_PATH = './Khoa_LHR_image/train'\n",
    "LHR_VAL_DATA_PATH = './Khoa_LHR_image/val'\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-sSscMVxqsV"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, is_train=True, is_phase1=False):\n",
    "        self.is_phase1 = is_phase1\n",
    "        self.is_train = is_train\n",
    "        self.img_dir = img_dir\n",
    "        self.images = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def normalize(self, input_image, target_image):\n",
    "        input_image  = input_image*2 - 1\n",
    "        target_image = target_image*2 - 1\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "    def random_jitter(self, input_image, target_image):\n",
    "        if torch.rand([]) < 0.5:\n",
    "            input_image = transforms.functional.hflip(input_image)\n",
    "            target_image = transforms.functional.hflip(target_image)\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "    def create_mask(self, image):\n",
    "        masked_image = image.copy()\n",
    "        ## Prepare masking matrix\n",
    "        mask = np.full((IMG_WIDTH,IMG_HEIGHT,3), 0, np.uint8)\n",
    "        for _ in range(np.random.randint(1, 5)):\n",
    "            # Get random x locations to start line\n",
    "            x1, x2 = np.random.randint(1, IMG_WIDTH), np.random.randint(1, IMG_WIDTH)\n",
    "            # Get random y locations to start line\n",
    "            y1, y2 = np.random.randint(1, IMG_HEIGHT), np.random.randint(1, IMG_HEIGHT)\n",
    "            # Get random thickness of the line drawn\n",
    "            thickness = np.random.randint(1, 15)\n",
    "            # Draw line on the black mask\n",
    "            cv2.line(mask,(x1,y1),(x2,y2),(1,1,1),thickness)\n",
    "\n",
    "        masked_image = np.where(mask, 255*np.ones_like(mask), masked_image)\n",
    "        return masked_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        if self.is_phase1:\n",
    "            image = transforms.functional.to_tensor(image)\n",
    "            input_image, target_image = self.normalize(image, image)\n",
    "            input_image, target_image = input_image.type(torch.float32), target_image.type(torch.float32)\n",
    "            if self.is_train:\n",
    "                input_image, target_image = self.random_jitter(input_image, target_image)\n",
    "            return input_image, target_image\n",
    "\n",
    "        input_image = self.create_mask(image)\n",
    "        input_image = transforms.functional.to_tensor(input_image)\n",
    "        target_image = transforms.functional.to_tensor(image)\n",
    "\n",
    "        input_image = input_image.type(torch.float32)\n",
    "        target_image = target_image.type(torch.float32)\n",
    "\n",
    "        input_image, target_image = self.normalize(input_image, target_image)\n",
    "\n",
    "        if self.is_train:\n",
    "            input_image, target_image = self.random_jitter(input_image, target_image)\n",
    "\n",
    "        return input_image, target_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyuoCauoxqsW"
   },
   "outputs": [],
   "source": [
    "train_dataset_phase1 = ImageDataset(LHR_TRAIN_DATA_PATH, is_train=True, is_phase1=True)\n",
    "train_loader_phase1 = DataLoader(train_dataset_phase1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset_phase1 = ImageDataset(LHR_VAL_DATA_PATH, is_train=False, is_phase1=True)\n",
    "test_loader_phase1 = DataLoader(test_dataset_phase1, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrN8jLj-xqsW",
    "outputId": "9a8b5b9d-871f-4616-adcb-f2905becbd67"
   },
   "outputs": [],
   "source": [
    "in_batch, tar_batch = next(iter(train_loader_phase1))\n",
    "in_batch = (in_batch + 1)/2\n",
    "tar_batch = (tar_batch + 1)/2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.squeeze(in_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.squeeze(tar_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.squeeze(in_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.squeeze(tar_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOELavroxqsW"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(LHR_TRAIN_DATA_PATH, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = ImageDataset(LHR_VAL_DATA_PATH, is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqI6nlHXxqsW",
    "outputId": "714a4161-342e-40ef-a3f5-e1d72006dc45"
   },
   "outputs": [],
   "source": [
    "in_batch, tar_batch = next(iter(train_loader))\n",
    "in_batch = (in_batch + 1)/2\n",
    "tar_batch = (tar_batch + 1)/2\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.squeeze(in_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "plt.imshow(np.squeeze(tar_batch[0].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.squeeze(in_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Input\")\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "plt.imshow(np.squeeze(tar_batch[1].numpy().transpose((1, 2, 0))))\n",
    "plt.title(\"Target\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9t2UF7NxqsW",
    "outputId": "fb443b2e-79e7-4c1b-a9e3-4020238d6713"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "IP_unet_model = II_Unet().to(device)\n",
    "IP_unet_model.to(device)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(IP_unet_model.parameters(), lr=1e-4, betas=[0.5,0.999])\n",
    "\n",
    "save_model = './UNET'\n",
    "os.makedirs(save_model, exist_ok = True)\n",
    "\n",
    "EPOCHS = 100\n",
    "IP_unet_model, metrics = train(\n",
    "    IP_unet_model, 'IP_unet_model_phase1', save_model, optimizer, criterion, train_loader_phase1, test_loader_phase1, EPOCHS, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HBdRItBxqsW",
    "outputId": "6903da5a-5810-41a7-b262-072bca3d2b02"
   },
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    EPOCHS,\n",
    "    metrics[\"train_psnr\"],\n",
    "    metrics[\"valid_psnr\"],\n",
    "    metrics[\"train_loss\"],\n",
    "    metrics[\"valid_loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfRqMUaGxqsW",
    "outputId": "49dee039-df44-4745-c7fb-c4d70576faca"
   },
   "outputs": [],
   "source": [
    "test_psnr, test_loss = evaluate_epoch(IP_unet_model, criterion, test_loader_phase1, device)\n",
    "test_psnr, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fY6enb_4xqsX",
    "outputId": "47bd0fb5-9ba9-426e-a5f3-8387f7362671"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, train_loader_phase1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEqCfa5nxqsX",
    "outputId": "bf9b6eaf-f156-40cd-8a68-f1d3cb6d51c2"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, test_loader_phase1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi8waS3ixqsZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQrGUMF-xqsZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkm7sdtBxqsZ",
    "outputId": "9362c44f-cd3b-45ac-8307-41c53b8323fb"
   },
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.Adam(IP_unet_model.parameters(), lr=1e-4, betas=[0.5,0.999])\n",
    "\n",
    "EPOCHS = 100\n",
    "IP_unet_model, metrics = train(\n",
    "    IP_unet_model, 'IP_unet_model_phase2', save_model, optimizer, criterion, train_loader, test_loader, EPOCHS, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqgKTREMxqsZ",
    "outputId": "054ad1d1-772d-4ba9-e03a-d8c39db18f8a"
   },
   "outputs": [],
   "source": [
    "plot_result(\n",
    "    EPOCHS,\n",
    "    metrics[\"train_psnr\"],\n",
    "    metrics[\"valid_psnr\"],\n",
    "    metrics[\"train_loss\"],\n",
    "    metrics[\"valid_loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7lpV7zaxqsa",
    "outputId": "5a9ef732-66c3-452c-b31b-a411da25b5b1"
   },
   "outputs": [],
   "source": [
    "test_psnr, test_loss = evaluate_epoch(IP_unet_model, criterion, test_loader, device)\n",
    "test_psnr, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WZCxebPxqsa",
    "outputId": "1d65d3dc-838f-430b-de40-d0a379cb0200"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMIvG6UFxqsa",
    "outputId": "31abaf36-84e1-4cff-dcc4-35975ee8432e"
   },
   "outputs": [],
   "source": [
    "predict_and_display(IP_unet_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
