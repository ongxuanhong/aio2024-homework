{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>likes_english</th>\n",
       "      <th>likes_ai</th>\n",
       "      <th>raise_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  likes_english  likes_ai  raise_salary\n",
       "0   23              0         0             0\n",
       "1   25              1         1             0\n",
       "2   27              1         0             1\n",
       "3   29              0         1             1\n",
       "4   29              0         0             0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"age\": [23, 25, 27, 29, 29],\n",
    "    \"likes_english\": [0, 1, 1, 0, 0],\n",
    "    \"likes_ai\": [0, 1, 0, 1, 0],\n",
    "    \"raise_salary\": [0, 0, 1, 1, 0],\n",
    "}\n",
    "\n",
    "pd_data = pd.DataFrame(data)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Scores: [np.float64(0.0), np.float64(0.25)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_gini(labels):\n",
    "    \"\"\"\n",
    "    Calculate the Gini impurity for a set of labels.\n",
    "\n",
    "    Args:\n",
    "        labels (array-like): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Gini impurity score.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each unique label\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    # Calculate the probability of each class\n",
    "    probabilities = counts / counts.sum()\n",
    "    # Calculate the Gini impurity\n",
    "    gini = 1 - np.sum(probabilities**2)\n",
    "    return gini\n",
    "\n",
    "\n",
    "def calculate_gini_score(feature_array, label_array):\n",
    "    \"\"\"\n",
    "    Calculate the Gini score for a dataset given features and labels.\n",
    "\n",
    "    Args:\n",
    "        feature_array (array-like): 2D array where each row is a data point and each column is a feature.\n",
    "        label_array (array-like): 1D array of labels corresponding to the data points.\n",
    "\n",
    "    Returns:\n",
    "        float: Gini score.\n",
    "    \"\"\"\n",
    "    gini_scores = []\n",
    "\n",
    "    for feature in range(feature_array.shape[1]):\n",
    "        # Get unique values of the feature\n",
    "        unique_values = np.unique(feature_array[:, feature])\n",
    "        gini_feature = 0\n",
    "\n",
    "        for value in unique_values:\n",
    "            # Get indices where feature value is equal to the unique value\n",
    "            indices = np.where(feature_array[:, feature] == value)\n",
    "            # Get corresponding labels\n",
    "            subset_labels = label_array[indices]\n",
    "            # Calculate Gini impurity for the subset\n",
    "            gini_value = calculate_gini(subset_labels)\n",
    "            # Calculate weighted Gini for the feature\n",
    "            weight = len(subset_labels) / len(label_array)\n",
    "            gini_feature += weight * gini_value\n",
    "\n",
    "        gini_scores.append(gini_feature)\n",
    "\n",
    "    return gini_scores\n",
    "\n",
    "\n",
    "# Example usage\n",
    "features = np.array([[1, 2], [1, 3], [2, 3], [2, 4]])\n",
    "labels = np.array([0, 0, 1, 1])\n",
    "\n",
    "gini_scores = calculate_gini_score(features, labels)\n",
    "print(\"Gini Scores:\", gini_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_gini(pd_data[\"raise_salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.4666666666666667), np.float64(0.4666666666666667)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_gini_score(\n",
    "    pd_data[[\"likes_ai\", \"raise_salary\"]].values, pd_data[\"likes_english\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_score_with_condition(df, feature, label, condition=None):\n",
    "    \"\"\"\n",
    "    Calculate the Gini score for a dataset given a feature, label, and condition.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing features and labels.\n",
    "        feature (str): Feature column name to split on.\n",
    "        label (str): Label column name to calculate Gini.\n",
    "        condition (callable, optional): Function to apply a condition on feature values.\n",
    "\n",
    "    Returns:\n",
    "        float: Gini score.\n",
    "    \"\"\"\n",
    "    if condition is None:\n",
    "        # No condition provided, calculate Gini for the entire dataset\n",
    "        labels = df[label].values\n",
    "        gini_score = calculate_gini(labels)\n",
    "    else:\n",
    "        # Apply condition\n",
    "        condition_met = df[feature].apply(condition)\n",
    "        # Subsets of data where condition is met and not met\n",
    "        subset_true = df[condition_met]\n",
    "        subset_false = df[~condition_met]\n",
    "\n",
    "        # Calculate Gini impurity for each subset\n",
    "        gini_true = calculate_gini(subset_true[label].values)\n",
    "        gini_false = calculate_gini(subset_false[label].values)\n",
    "\n",
    "        # Weighted Gini score\n",
    "        weight_true = len(subset_true) / len(df)\n",
    "        weight_false = len(subset_false) / len(df)\n",
    "        gini_score = weight_true * gini_true + weight_false * gini_false\n",
    "\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Score for age <= 26: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "gini_score_age = calculate_gini_score_with_condition(\n",
    "    pd_data, feature=\"age\", label=\"raise_salary\", condition=(lambda x: x <= 26)\n",
    ")\n",
    "print(\"Gini Score for age <= 26:\", gini_score_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(labels):\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a set of labels.\n",
    "\n",
    "    Args:\n",
    "        labels (array-like): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Entropy score.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each unique label\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    # Calculate the probability of each class\n",
    "    probabilities = counts / counts.sum()\n",
    "    # Calculate entropy, ignoring zero probabilities to avoid log(0)\n",
    "    entropy = -np.sum(\n",
    "        probabilities * np.log2(probabilities, where=(probabilities != 0))\n",
    "    )\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_entropy_score(feature_array, label_array):\n",
    "    \"\"\"\n",
    "    Calculate the entropy score for a dataset given features and labels.\n",
    "\n",
    "    Args:\n",
    "        feature_array (array-like): 2D array where each row is a data point and each column is a feature.\n",
    "        label_array (array-like): 1D array of labels corresponding to the data points.\n",
    "\n",
    "    Returns:\n",
    "        list of float: Entropy scores for each feature.\n",
    "    \"\"\"\n",
    "    entropy_scores = []\n",
    "\n",
    "    for feature in range(feature_array.shape[1]):\n",
    "        # Get unique values of the feature\n",
    "        unique_values = np.unique(feature_array[:, feature])\n",
    "        entropy_feature = 0\n",
    "\n",
    "        for value in unique_values:\n",
    "            # Get indices where feature value is equal to the unique value\n",
    "            indices = np.where(feature_array[:, feature] == value)\n",
    "            # Get corresponding labels\n",
    "            subset_labels = label_array[indices]\n",
    "            # Calculate entropy for the subset\n",
    "            entropy_value = calculate_entropy(subset_labels)\n",
    "            # Calculate weighted entropy for the feature\n",
    "            weight = len(subset_labels) / len(label_array)\n",
    "            entropy_feature += weight * entropy_value\n",
    "\n",
    "        entropy_scores.append(entropy_feature)\n",
    "\n",
    "    return entropy_scores\n",
    "\n",
    "\n",
    "def calculate_entropy_score_with_condition(df, feature, label, condition=None):\n",
    "    \"\"\"\n",
    "    Calculate the entropy score for a dataset given a feature, label, and condition.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing features and labels.\n",
    "        feature (str): Feature column name to split on.\n",
    "        label (str): Label column name to calculate entropy.\n",
    "        condition (callable, optional): Function to apply a condition on feature values.\n",
    "\n",
    "    Returns:\n",
    "        float: Entropy score.\n",
    "    \"\"\"\n",
    "    if condition is None:\n",
    "        # No condition provided, calculate entropy for the entire dataset\n",
    "        labels = df[label].values\n",
    "        entropy_score = calculate_entropy(labels)\n",
    "    else:\n",
    "        # Apply condition\n",
    "        condition_met = df[feature].apply(condition)\n",
    "        # Subsets of data where condition is met and not met\n",
    "        subset_true = df[condition_met]\n",
    "        subset_false = df[~condition_met]\n",
    "\n",
    "        # Calculate entropy for each subset\n",
    "        entropy_true = calculate_entropy(subset_true[label].values)\n",
    "        entropy_false = calculate_entropy(subset_false[label].values)\n",
    "\n",
    "        # Weighted entropy score\n",
    "        weight_true = len(subset_true) / len(df)\n",
    "        weight_false = len(subset_false) / len(df)\n",
    "        entropy_score = weight_true * entropy_true + weight_false * entropy_false\n",
    "\n",
    "    return entropy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9709505944546686)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_entropy(pd_data[\"raise_salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.02904940554533142)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - calculate_entropy(pd_data[\"likes_english\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9509775004326937), np.float64(0.9509775004326937)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_entropy_score(\n",
    "    pd_data[[\"likes_ai\", \"raise_salary\"]].values, pd_data[\"likes_english\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04902249956730631"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.9509775004326937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "print(iris_X.shape)\n",
    "print(iris_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paragraph C:\n",
    "# Load the diabetes dataset\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Paragraph B:\n",
    "# Define model\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Split train : test = 8:2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_X, iris_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Paragraph A:\n",
    "# Train\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Paragraph D:\n",
    "# Preidct and evaluate\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
